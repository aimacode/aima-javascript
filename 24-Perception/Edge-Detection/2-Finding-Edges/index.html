<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
	<title>Edge Detection - Finding Edges</title>

	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css"
		integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
	<link rel="stylesheet" href="https://code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css">
	<link rel="stylesheet" href="/styles.css">
	<link rel="stylesheet" href="../style.css">
	<script src="https://code.jquery.com/jquery-1.12.4.js"></script>
	<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>

	<script type="text/javascript" src="/main.js"></script>
</head>

<body class="flex-content-container">
	<div class="flex-content">
		<div class="content-container" id="content">

			<br>
			<div class="row">
				<div class="col-sm-6 text-left">
					<a href="../1-Introduction/"><i class="fas fa-arrow-left"></i> Prev</a>
				</div>
			</div>

			<div style="display: flex; flex-direction: column; row-gap: 1em;">
				<h1>Finding Edges</h1>

				<p>
					How do we approach the problem of finding edges? We have defined edges as locations where drastic
					changes in intensity occur, but we do not have a way of quantifying this intensity change.
				</p>

				<h2>Calculating Intensity Change</h2>

				<p>
					To aid us in our problem-solving, let us take a step back and re-imagine our problem.
					Suppose our pixel array is put into 3D space as a topological map where the intensity of
					each pixel becomes some height. It may look something like the example shown below.
				</p>

				<div id="topology-root"></div>

				<p>
					Picking some point on this map, we want to figure out the change in height around that
					point. Knowing our pointâ€™s height alone is relatively unhelpful since, although it may tell us how
					high up it is, we get no information about how the height has changed. What if, in addition, we also
					considered the heights of points a small radius away from our chosen point? Ah-hah! Now by comparing
					these nearby heights, we can get some idea of the local changes around our point!
				</p>

				<img src="../images/elevation.png" alt="Elevation comparison example" class="center display-image">

				<p>
					This intuition is the driving principle behind a well-known edge detector called the <strong>Sobel
						operator</strong>. The operator works by dragging two <strong>kernels</strong> or
					<strong>filters</strong> called Sobel X and Sobel Y across an image to calculate horizontal and
					vertical intensity changes respectively. For each target pixel in the image, the kernel selects and
					performs an operation on a neighborhood of surrounding pixels. This compares the intensity of the
					neighboring pixels with each other and uses them to compute the change in intensity at the target
					pixel. To demonstrate this, below are two interactive examples using the Sobel X
					and Sobel Y filters. Drag the filters around and see how different areas reflect different
					intensity changes.
				</p>

				<div id="convolution-root-x"></div>
				<div id="convolution-root-y"></div>

				<div class="blurb-container">
					<h4><strong>Math in the Filter</strong></h4>
					<p>
						Under the hood, filters are grids of numerical weights that are matched up to each neighborhood
						of pixels. The filter weights and the pixel intensities are used to calculate a weighted sum
						that represents the change at each target pixel. This general process of dragging a grid across
						a larger grid is called <strong>cross correlation</strong>. Doing this with a flipped filter is
						a slightly different process called <strong>convolution</strong>. In general, we prefer doing
						convolutions because of their nice mathematical properties, such as being able to
						compose many convolutions into one convolution.
					</p>
				</div>

				<h2>Change as a Vector</h2>

				<p>
					The end result of applying both the Sobel X and Sobel Y filters to our image is two new pixel arrays
					containing values that represent horizontal and vertical changes respectively. These values can also
					be thought of as the X and Y components for a grid of 2D arrows or <strong>vectors</strong>.
					The vectors gotten using the Sobel operator are known as <strong>gradients</strong>. For a given
					pixel, the magnitude of the gradient tells us how much overall intensity change occurs at that pixel
					and the angle tells us the general direction of that intensity change.
				</p>

				<p>
					Below is a demonstration that illustrates these gradients. Draw edges or select one of the preset
					images and observe how the direction and magnitude of the gradient vectors change in response.
				</p>

				<div id="gradient-root"></div>

				<p>
					So far, our algorithm consists of taking a color image, converting it to grayscale intensities,
					and applying the Sobel operator to it to find the image's gradients. Observing the magnitudes
					of these gradients, we can already see edges begin to manifest as brighter pixels where intensity
					change is strong.
				</p>

				<div id="pipeline2d-short-root"></div>

				<h2>Problems and Shortcomings</h2>

				<p>
					Plugging images through this algorithm, you may have already noticed that Sobel by itself
					does not perform very well. Our edge detection is not very good at producing clean and precise
					edges, nor is it very good at dealing with grainy images.
				</p>

				<div id="pipeline2d-grainy-root"></div>

				<p>
					To make edge detection robust, several pre and post-processing steps are required along with Sobel.
					In fact, our current algorithm with these additional steps was formulated in 1986 by John Canny and
					is what we know today as <strong>Canny edge detection</strong>. The full Canny edge detection
					pipeline can be seen below.
				</p>

				<div id="pipeline2d-long-root"></div>

				<h2>Summary</h2>

				<p>
					One way to approach detecting edges is to compare a given pixel's neighbors with each other
					to evaluate local changes in intensity. This is the principle that the Sobel operator uses to detect
					edges and generate gradients. While Sobel acts as the core of edge detection, several extra
					steps are required to make it robust. The addition of these extra steps to Sobel forms a
					widely-used edge detection algorithm known as Canny edge detection which is still popular
					in computer vision today.
				</p>

			</div>

			<hr>
			<div class="row">
				<div class="col-sm-6 text-left">
					<a href="../1-Introduction/"><i class="fas fa-arrow-left"></i> Prev</a>
				</div>
			</div>
			<br>
		</div>
	</div>


	<!-- Replace with third party -->
	<script crossorigin src="https://unpkg.com/react@16/umd/react.development.js"></script>
	<script crossorigin src="https://unpkg.com/react-dom@16/umd/react-dom.development.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/106/three.js"></script>
	<script src="/third-party/vis.min.js"></script>

	<script type="text/javascript" src="../js/setup.js"></script>

	<script type="text/javascript" src="../js/util.js"></script>
	<script type="text/javascript" src="../js/imageProcessing.js"></script>
	<script type="text/javascript" src="../js/ui.js"></script>
	<script type="text/javascript" src="../js/demos/pipeline2d/pipelineHelpers.js"></script>

	<script type="text/javascript" src="../js/demos/TopologyDemo.js"></script>
	<script type="text/javascript" src="../js/demos/ConvolutionDemo.js"></script>
	<script type="text/javascript" src="../js/demos/GradientDemo.js"></script>
	<script type="text/javascript" src="../js/demos/pipeline2d/Pipeline2dShortDemo.js"></script>
	<script type="text/javascript" src="../js/demos/pipeline2d/Pipeline2dLongDemo.js"></script>
	<script type="text/javascript" src="../js/demos/pipeline2d/Pipeline2dGrainyDemo.js"></script>

	<script>
		ReactDOM.render(
			e(TopologyDemo, null, null),
			document.getElementById('topology-root')
		);

		ReactDOM.render(
			e(ConvolutionDemo, { filterType: 'sobelX' }, null),
			document.getElementById('convolution-root-x')
		);
		ReactDOM.render(
			e(ConvolutionDemo, { filterType: 'sobelY' }, null),
			document.getElementById('convolution-root-y')
		);

		ReactDOM.render(
			e(GradientDemo, null, null),
			document.getElementById('gradient-root')
		);

		ReactDOM.render(
			e(Pipeline2dShortDemo, null, null),
			document.getElementById('pipeline2d-short-root')
		);

		ReactDOM.render(
			e(Pipeline2dLongDemo, null, null),
			document.getElementById('pipeline2d-long-root')
		);

		ReactDOM.render(
			e(Pipeline2dGrainyDemo, null, null),
			document.getElementById('pipeline2d-grainy-root')
		);
	</script>

</body>

</html>