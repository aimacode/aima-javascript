<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
	<title>Edge Detection - Robust Edge Detection</title>

	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css"
		integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
	<link rel="stylesheet" href="https://code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css">
	<link rel="stylesheet" href="/styles.css">
	<link rel="stylesheet" href="../style.css">
	<script src="https://code.jquery.com/jquery-1.12.4.js"></script>
	<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>
	<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/jqueryui-touch-punch/0.2.3/jquery.ui.touch-punch.min.js"></script>

	<script type="text/javascript" src="/main.js"></script>
</head>

<body class="flex-content-container">
	<div class="flex-content">
		<div class="content-container" id="content">
			<div style="display: flex; flex-direction: column; row-gap: 1em;">

				<h1>Robust Edge Detection</h1>
				<p>
					The Sobel operator alone is not capable of producing very clean edges. Two major issues with our
					current algorithm are that it performs poorly on noisy inputs and that it produces very vague and
					blurry edges. Ideally, our edge detection algorithm should be able to compensate for poor input
					quality and be able to pinpoint the location of edges to a fine degree.
				</p>

				<h2>Gaussian Smoothing</h2>
				<p>
					Right now, our algorithm is very susceptible to <strong>noise</strong>, tending to classify a single
					bright pixel in a sea of dark pixels as an edge, which is not what we want.
				</p>

				<img src="/third-party/shannon-01.png" alt="Edge detection on noisy input" class="center display-image">

				<p>
					To deal with this, we can choose to reduce noise in an image with a technique called
					<strong>Gaussian smoothing</strong> before applying the Sobel operator. The way Gaussian smoothing
					is done is very similar to that of Sobel. Both use filters and convolution to change the original
					image: The only difference is that with Gaussian smoothing, the filter is an approximation of the
					<strong>normal distribution</strong> with two inputs shown below.
				</p>

				<img src="/third-party/gaussian-2d.png" alt="2D gaussian function" class="center display-image">

				<p>
					Intuitively, this filter balances a target pixel’s intensity by considering the target as well as
					its neighbors to a lesser degree the farther away they are. This has the effect of smoothing out an
					image and reducing noise which improves the performance the Sobel operator.
				</p>

				<img src="/third-party/shannon-02.png" alt="Edge detection on noisy input after gaussian blur"
					class="center display-image">

				<h2>Non-Maximum Suppression</h2>
				<p>
					In addition to noise reduction, we want to be able to precisely say where our edges are. This would
					mean taking the thick edges given to us by the Sobel operator and thinning them down to produce
					finer edge boundaries.
				</p>

				<p>
					One way to thin edges is to perform <strong>non-maximum suppression</strong> where we keep only the
					strongest edge pixels. Non-maximum suppression works by observing the two neighboring pixels along a
					target pixel’s gradient. If the target has the largest gradient magnitude among the three, it is
					kept, otherwise, it is suppressed.
				</p>

				<p>
					Below is a demonstration of non-maximum suppression on a single pixel. Remember that the vectors of
					greatest magnitude are red and that we are suppressing pixels on a basis of gradient magnitude and
					not pixel intensity.
				</p>

				<div id="suppression-root"></div>

				<h2>Double Threshold</h2>
				<p>
					While non-maximum suppression gets rid of most of the unwanted pixels along an edge, some get left
					behind. We can clean them up by performing a <strong>double threshold</strong> which sets an
					empirically-determined high and low threshold to classify and cull pixels. Pixels above the high
					threshold are marked as strong edges, pixels between the high and low thresholds are marked as weak
					edges, and pixels below the low threshold are suppressed.
				</p>

				<div id="threshold-root"></div>

				<h2>Edge Tracking by Hysteresis</h2>
				<p>
					At this stage, we are still left with several wrongly marked edges. While strong edges are most
					likely true edges, weak edges could be true edges or may simply be badly classified. How do we
					determine which weak edges to keep and which to throw away? Usually, the weak edges that we want are
					connected or adjacent to strong edges while the unwanted weak edges are isolated. Thus it is
					possible to do <strong>blob analysis</strong> where we search each weak edge’s 8-pixel neighborhood
					for a strong edge. If a strong edge exists in the neighborhood, the weak edge is kept, otherwise it
					is thrown away.
				</p>

				<img src="../images/blobAnalysis.png" alt="Example of keeping or suppressing weak edge using blob"
					class="center display-image">

				<h2>Canny Edge Detection</h2>
				<p>
					We could keep processing our image and fine tuning our algorithm, but usually images at this stage
					have their edges detected reasonably well. From a photograph, we have managed to apply a sequence of
					techniques that extracts edges to some degree of satisfaction. This pipeline as a whole is an
					algorithm known as <strong>Canny edge detection</strong>, created by John Canny in 1986. Despite its
					age and various improvements in computer vision and computing power since it was first conceived,
					Canny edge detection still remains one of the most effective and widely-used edge detection
					algorithms today.
				</p>

				<p>
					In summary, edge detection provides a way for machines to decode visual information by simplifying a
					complex image into one that illustrates the boundaries of objects in a scene.
				</p>

				<p>
					To do edge detection on a color image, we perform the following sequence of steps on an image:
				</p>

				<ul>
					<li>
						<p>Conversion from color to grayscale intensities</p>
					</li>
					<li>
						<p>Gaussian smoothing to reduce noise</p>
					</li>
					<li>
						<p>Sobel operator to crudely find edges</p>
					</li>
					<li>
						<p>Non-maximum suppression to thin the edges</p>
					</li>
					<li>
						<p>Double threshold and hysteresis to clean up</p>
					</li>
				</ul>

				<p>
					This sequence is an early edge-detection algorithm famously known as Canny edge detection. In
					general, edge detection opens many doors within computer vision, serving as a stepping stone for
					more complicated algorithms such as those dealing with image segmentation or object detection.
				</p>

				<div id="pipeline2d-long-root"></div>

			</div>

			<hr>
			<div class="row">
				<div class="col-sm-6 text-left">
					<a href="../2-Finding-Edges/"><i class="fas fa-arrow-left"></i> Prev</a>
				</div>
				<div class="col-sm-6 text-right">
				</div>
			</div>
			<br>
		</div>

	</div>


	<!-- Replace with third party -->
	<script crossorigin src="https://unpkg.com/react@16/umd/react.development.js"></script>
	<script crossorigin src="https://unpkg.com/react-dom@16/umd/react-dom.development.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.21.0/vis.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/106/three.js"></script>
	<script src="/third-party/OrbitControls.js"></script>


	<script type="text/javascript" src="../js/setup.js"></script>
	<script type="module" src="../js/loaders/loaderPart3.js"></script>

</body>

</html>